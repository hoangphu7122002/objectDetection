{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "streaming_video.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RIYBPEv8Vh62"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import base64\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from scipy import spatial"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RISaG76WWYOb",
        "outputId": "528ca682-34bb-4ac1-a829-ac95ee0f7c3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hoangphu7122002/Yolo-Vehicle-Counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgqv4X3wY9qt",
        "outputId": "50b466ee-9dea-44fa-9151-e726d468ae09"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Yolo-Vehicle-Counter'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 123 (delta 29), reused 42 (delta 16), pack-reused 60\u001b[K\n",
            "Receiving objects: 100% (123/123), 39.90 MiB | 19.48 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P /content/ https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "devH5xCLZJ29",
        "outputId": "fc56b815-a619-4d0b-e7f4-6d7729d5b98c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-13 16:21:11--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘/content/yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  72.1MB/s    in 3.5s    \n",
            "\n",
            "2022-04-13 16:21:15 (67.5 MB/s) - ‘/content/yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_path = \"/content/Yolo-Vehicle-Counter/yolo-coco/coco.names\"\n",
        "\n",
        "#handle label path\n",
        "LABELS = open(label_path).read().strip().split(\"\\n\")\n",
        "np.random.seed(42)\n",
        "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")\n",
        "\n",
        "#handle weight path\n",
        "weightsPath = \"/content/yolov3.weights\"\n",
        "\n",
        "\n",
        "#handle config_path\n",
        "configPath = \"/content/Yolo-Vehicle-Counter/yolo-coco/yolov3.cfg\"\n",
        "\n",
        "YOLOnet = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
      ],
      "metadata": {
        "id": "ODrZ-KZtZaFC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ln = YOLOnet.getLayerNames()\n",
        "ln = [ln[i[0] - 1] for i in YOLOnet.getUnconnectedOutLayers()]"
      ],
      "metadata": {
        "id": "gEUfr1b_Zy6D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def start_input():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'When finished, click here or on the video to stop this demo</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 512; //video.videoWidth;\n",
        "      captureCanvas.height = 512; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function takePhoto(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def take_photo(label, img_data):\n",
        "  data = eval_js('takePhoto(\"{}\", \"{}\")'.format(label, img_data))\n",
        "  return data"
      ],
      "metadata": {
        "id": "d7LKCMh6cnUo"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def js_reply_to_image(js_reply):\n",
        "    \"\"\"\n",
        "    input: \n",
        "          js_reply: JavaScript object, contain image from webcam\n",
        "\n",
        "    output: \n",
        "          image_array: image array RGB size 512 x 512 from webcam\n",
        "    \"\"\"\n",
        "    jpeg_bytes = base64.b64decode(js_reply['img'].split(',')[1])\n",
        "    image_PIL = Image.open(io.BytesIO(jpeg_bytes))\n",
        "    image_array = np.array(image_PIL)\n",
        "\n",
        "    return image_array\n",
        "\n",
        "def bbox_to_bytes(bbox_array):\n",
        "    \"\"\"\n",
        "    Params:\n",
        "            bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "    Returns:\n",
        "          bytes: Base64 image byte string\n",
        "    \"\"\"\n",
        "    # convert array into PIL image\n",
        "    bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "    iobuf = io.BytesIO()\n",
        "    # format bbox into png for return\n",
        "    bbox_PIL.save(iobuf, format='png')\n",
        "    # format return string\n",
        "    bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "    return bbox_bytes"
      ],
      "metadata": {
        "id": "TIzGmsSlX1FW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global variable**"
      ],
      "metadata": {
        "id": "WOxhIs9O1o9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FRAMES_BEFORE_CURRENT = 25"
      ],
      "metadata": {
        "id": "cK7sg5DU1saa"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Count object**"
      ],
      "metadata": {
        "id": "rJoYzeMNz1JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def displayVehicleCount(frame, object_count):\n",
        "    return cv2.putText(\n",
        "      frame, #Image\n",
        "      'Detected object: ' + str(object_count), #Label\n",
        "      (20, 20), #Position\n",
        "      cv2.FONT_HERSHEY_SIMPLEX, #Font\n",
        "      0.8, #Size\n",
        "      (0, 0xFF, 0), #Color\n",
        "      2, #Thickness\n",
        "      cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
        "      )\n",
        "\n",
        "def box_in_previous_frame(previous_frame_detections, current_box, current_detections):\n",
        "    centerX, centerY, width, height = current_box\n",
        "    dist = np.inf \n",
        "\n",
        "    for i in range(FRAMES_BEFORE_CURRENT):\n",
        "        coordinate_list = list(previous_frame_detections[i].keys())\n",
        "        \n",
        "        if len(coordinate_list) == 0: # When there are no detections in the previous frame\n",
        "          continue\n",
        "        temp_dist, index = spatial.KDTree(coordinate_list).query([(centerX, centerY)])\n",
        "\n",
        "        if (temp_dist < dist):\n",
        "            dist = temp_dist\n",
        "            frame_num = i\n",
        "            coord = coordinate_list[index[0]]\n",
        "        \n",
        "        if (dist > (max(width, height)/2)):\n",
        "\t\t        return False\n",
        "    \n",
        "    current_detections[(centerX, centerY)] = previous_frame_detections[frame_num][coord]\n",
        "    return True\n",
        "\n",
        "def drawDetectionBoxes(idxs, boxes, classIDs, confidences, bbox_array,object_count):\n",
        "    # ensure at least one detection exists\n",
        "    if len(idxs) > 0:\n",
        "      # loop over the indices we are keeping\n",
        "      for i in idxs.flatten():\n",
        "        # extract the bounding box coordinates\n",
        "        (x, y) = (boxes[i][0], boxes[i][1])\n",
        "        (w, h) = (boxes[i][2], boxes[i][3])\n",
        "\n",
        "        # draw a bounding box rectangle and label on the frame\n",
        "        color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "        bbox_array = cv2.rectangle(bbox_array, (x, y), (x + w, y + h), color, 2)\n",
        "        text = \"{}: {:.4f}\".format(LABELS[classIDs[i]],\n",
        "          confidences[i])\n",
        "        bbox_array = cv2.putText(bbox_array, text, (x, y - 5),\n",
        "          cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "        #Draw a green dot in the middle of the box\n",
        "        bbox_array = cv2.circle(bbox_array, (x + (w//2), y+ (h//2)), 2, (0, 0xFF, 0), thickness=2)\n",
        "        object_count += 1\n",
        "    return bbox_array, object_count"
      ],
      "metadata": {
        "id": "jdC9ifs6ekiJ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def count_object(idxs, boxes, classIDs, object_count, previous_frame_detections, bbox_array,list_of_object = [\"person\"]):\n",
        "#     current_detections = {}\n",
        "\n",
        "#     if len(idxs) > 0:\n",
        "# \t\t# loop over the indices we are keeping\n",
        "#         for i in idxs.flatten():\n",
        "#           # extract the bounding box coordinates\n",
        "#           (x, y) = (boxes[i][0], boxes[i][1])\n",
        "#           (w, h) = (boxes[i][2], boxes[i][3])\n",
        "          \n",
        "#           centerX = x + (w//2)\n",
        "#           centerY = y + (h//2)\n",
        "\n",
        "#           # When the detection is in the list of vehicles, AND\n",
        "#           # it crosses the line AND\n",
        "#           # the ID of the detection is not present in the vehicles\n",
        "#           if (LABELS[classIDs[i]] in list_of_object):\n",
        "#               current_detections[(centerX, centerY)] = object_count \n",
        "#               if (not box_in_previous_frame(previous_frame_detections, (centerX, centerY, w, h), current_detections)):\n",
        "#                   object_count += 1\n",
        "#                 # vehicle_crossed_line_flag += True\n",
        "#               # else: #ID assigning\n",
        "#                 #Add the current detection mid-point of box to the list of detected items\n",
        "#               # Get the ID corresponding to the current detection\n",
        "\n",
        "#               ID = current_detections.get((centerX, centerY))\n",
        "#               # If there are two detections having the same ID due to being too close, \n",
        "#               # then assign a new ID to current detection.\n",
        "#               if (list(current_detections.values()).count(ID) > 1):\n",
        "#                 current_detections[(centerX, centerY)] = object_count\n",
        "#                 object_count += 1 \n",
        "\n",
        "#               #Display the ID at the center of the box\n",
        "#               bbox_array = cv2.putText(bbox_array, str(ID), (centerX, centerY),cv2.FONT_HERSHEY_SIMPLEX, 0.5, [0,0,255], 2)\n",
        "    \n",
        "#     return object_count, current_detections"
      ],
      "metadata": {
        "id": "_MNE9xE-0owE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previous_frame_detections = [{(0,0):0} for i in range(FRAMES_BEFORE_CURRENT)]\n",
        "num_frames, object_count = 0, 0\n",
        "\n",
        "start_input()\n",
        "\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "while True:\n",
        "    js_reply = take_photo(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_reply_to_image(js_reply)\n",
        "\n",
        "    W,H = img.shape[:2]\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    # # grayscale image for face detection\n",
        "    # gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # # get face region coordinates\n",
        "    # faces = face_cascade.detectMultiScale(gray)\n",
        "    # # get face bounding box for overlay\n",
        "    # for (x,y,w,h) in faces:\n",
        "    #   bbox_array = cv2.rectangle(bbox_array,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (416, 416),\n",
        "\t\tswapRB=True, crop=False)\n",
        "\n",
        "    YOLOnet.setInput(blob)\n",
        "    start = time.time()\n",
        "    layerOutputs = YOLOnet.forward(ln)\n",
        "    end = time.time()\n",
        "    \n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    classIDs = []\n",
        "\n",
        "    for output in layerOutputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            classID = np.argmax(scores)\n",
        "            confidence = scores[classID]\n",
        "\n",
        "            if confidence > 0.9:\n",
        "                box = detection[0:4] * np.array([W, H, W, H])\n",
        "                centerX, centerY, width, height = box.astype(\"int\")\n",
        "\n",
        "                x = int(centerX - (width / 2))\n",
        "                y = int(centerY - (height / 2))\n",
        "\n",
        "                boxes.append([x, y, int(width), int(height)])\n",
        "                confidences.append(float(confidence))\n",
        "                classIDs.append(classID)\n",
        "\n",
        "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.9, 0.3)\n",
        "\n",
        "    # if len(idxs) > 0:\n",
        "    #   for i in idxs.flatten():\n",
        "    #     (x, y) = (boxes[i][0], boxes[i][1])\n",
        "    #     (w, h) = (boxes[i][2], boxes[i][3])\n",
        "    #     color = [int(c) for c in COLORS[classIDs[i]]]\n",
        "    #     bbox_array = cv2.rectangle(bbox_array, (x, y), (x + w, y + h), color, 2)\n",
        "    #     text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
        "    #     bbox_array = cv2.putText(bbox_array, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "    #       0.5, color, 2) \n",
        "    bbox_array,object_count = drawDetectionBoxes(idxs, boxes, classIDs, confidences, bbox_array,object_count)\n",
        "    # object_count,current_detections = count_object(idxs, boxes, classIDs, object_count, previous_frame_detections, bbox_array,list_of_object = [\"person\"])\n",
        "    displayVehicleCount(bbox_array, object_count)\n",
        "    object_count = 0\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "\t\t   break\t\n",
        "\n",
        "    # previous_frame_detections.pop(0)\n",
        "    # previous_frame_detections.append(current_detections)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Fj-Zwv68YMT-",
        "outputId": "60ee21bf-548e-4517-ba4b-bde0c63ac82f"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "    \n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "    \n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "    \n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 512, 512);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "    \n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "      \n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "           \n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "      \n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML = \n",
              "          '<span style=\"color: red; font-weight: bold;\">' +\n",
              "          'When finished, click here or on the video to stop this demo</span>';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "      \n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 512; //video.videoWidth;\n",
              "      captureCanvas.height = 512; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "      \n",
              "      return stream;\n",
              "    }\n",
              "    async function takePhoto(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "      \n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "            \n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "      \n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "      \n",
              "      return {'create': preShow - preCreate, \n",
              "              'show': preCapture - preShow, \n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PGlb4w-C_B_2"
      },
      "execution_count": 50,
      "outputs": []
    }
  ]
}